{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "  \"\"\"Counts the number of files in a given directory.\n",
    "\n",
    "  Args:\n",
    "    directory: The path to the directory.\n",
    "\n",
    "  Returns:\n",
    "    The number of files in the directory.\n",
    "  \"\"\"\n",
    "\n",
    "  num_files = 0\n",
    "  for root, _, files in os.walk(directory):\n",
    "    num_files += len(files)\n",
    "  return num_files\n",
    "\n",
    "# Example usage:\n",
    "directory_path = \"./dataset/images\"\n",
    "file_count = count_files(directory_path)\n",
    "print(\"Number of files:\", file_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "  \"\"\"Counts the number of files in a given directory.\n",
    "\n",
    "  Args:\n",
    "    directory: The path to the directory.\n",
    "\n",
    "  Returns:\n",
    "    The number of files in the directory.\n",
    "  \"\"\"\n",
    "\n",
    "  num_files = 0\n",
    "  for root, _, files in os.walk(directory):\n",
    "    num_files += len(files)\n",
    "  return num_files\n",
    "\n",
    "# Example usage:\n",
    "directory_path = \"./dataset/labels\"\n",
    "file_count = count_files(directory_path)\n",
    "print(\"Number of files:\", file_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01metree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mElementTree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mET\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\sklearn\\__init__.py:84\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     87\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     ]\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\sklearn\\utils\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\sklearn\\utils\\_chunking.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\sklearn\\utils\\_array_api.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[0;32m     13\u001b[0m _NUMPY_NAMESPACE_NAMES \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray_api_compat.numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21myield_namespaces\u001b[39m(include_numpy_namespaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\sklearn\\utils\\fixes.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_packaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_threadpool_controller\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\scipy\\stats\\__init__.py:610\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    605\u001b[0m \n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    609\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 610\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\scipy\\stats\\_stats_py.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distance_matrix\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m milp, LinearConstraint\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, _get_nan,\n\u001b[0;32m     42\u001b[0m                               _rename_parameter, _contains_nan,\n\u001b[0;32m     43\u001b[0m                               AxisError)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\scipy\\optimize\\__init__.py:417\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_minimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_root\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 417\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_root_scalar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_minpack_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_zeros_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\scipy\\optimize\\_root_scalar.py:11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mUnified interfaces to root finding algorithms for real or complex\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mscalar functions.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m- root : find a root of a scalar function.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _zeros_py \u001b[38;5;28;01mas\u001b[39;00m optzeros\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_numdiff\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m approx_derivative\n\u001b[0;32m     14\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot_scalar\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1577\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:161\u001b[0m, in \u001b[0;36m_path_isfile\u001b[1;34m(path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:153\u001b[0m, in \u001b[0;36m_path_is_mode_type\u001b[1;34m(path, mode)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "image_dir = './dataset/images'\n",
    "label_dir = './dataset/labels'\n",
    "\n",
    "# Function to parse XML and extract label\n",
    "def parse_xml(label_path):\n",
    "    tree = ET.parse(label_path)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        return 1 if label == 'varroa_mite' else 0\n",
    "\n",
    "# Load images and labels\n",
    "def load_data(image_dir, label_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for img_name in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        label_path = os.path.join(label_dir, img_name.replace('.jpg', '.xml'))\n",
    "        \n",
    "        # Load image\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(128, 128))\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "        images.append(img)\n",
    "        \n",
    "        # Load label\n",
    "        label = parse_xml(label_path)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_data(image_dir, label_dir)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown variable: <KerasVariable shape=(3, 3, 3, 32), dtype=float32, path=sequential/conv2d/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:228\u001b[0m, in \u001b[0;36mBaseOptimizer._check_variables_are_known\u001b[1;34m(self, variables)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(v) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables_indices:\n\u001b[1;32m--> 228\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    229\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This optimizer can only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe called for the variables it was originally built with. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen working with a new set of variables, you should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecreate a new optimizer instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown variable: <KerasVariable shape=(3, 3, 3, 32), dtype=float32, path=sequential/conv2d/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Test accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('varroa_mite_detector.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001AF11A36E60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001AF11A36E60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = tf.keras.models.load_model('varroa_mite_detector.h5')\n",
    "\n",
    "# Predict on new images\n",
    "def predict(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    return np.argmax(prediction, axis=1)\n",
    "\n",
    "# Example usage\n",
    "image_path = './dataset/images/IMG_5994.jpg'\n",
    "prediction = predict(image_path, model)\n",
    "print('Prediction:', 'Varroa mite' if prediction == 1 else 'No mite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step\n",
      "Filename: IMG_5536.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5559.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5560.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5561.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5562.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Filename: IMG_5582.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Filename: IMG_5583.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5584.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Filename: IMG_5585.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Filename: IMG_5629.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5630.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Filename: IMG_5631.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Filename: IMG_5651.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Filename: IMG_5652.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5654.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Filename: IMG_5674.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Filename: IMG_5675.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5676.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5677.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5699.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Filename: IMG_5700.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Filename: IMG_5701.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "Filename: IMG_5702.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Filename: IMG_5722.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5723.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Filename: IMG_5724.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5725.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Filename: IMG_5745.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5746.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5747.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Filename: IMG_5748.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Filename: IMG_5769.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Filename: IMG_5770.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Filename: IMG_5771.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5791.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5792.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Filename: IMG_5793.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Filename: IMG_5794.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Filename: IMG_5814.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Filename: IMG_5815.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Filename: IMG_5816.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Filename: IMG_5817.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Filename: IMG_5838.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Filename: IMG_5861.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5862.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5863.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5864.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Filename: IMG_5884.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Filename: IMG_5885.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5887.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Filename: IMG_5907.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5908.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Filename: IMG_5909.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5910.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5956.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5957.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Filename: IMG_5958.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Filename: IMG_5959.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5979.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Filename: IMG_5980.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5981.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Filename: IMG_5982.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Filename: IMG_5993.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Filename: IMG_5994.jpg, Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('varroa_mite_detector.h5')\n",
    "\n",
    "def predict_image(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    prediction = model.predict(img)\n",
    "    return np.argmax(prediction, axis=1)\n",
    "\n",
    "# Function to process all images in a folder\n",
    "def process_images(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            prediction = predict_image(image_path, model)\n",
    "            print(f\"Filename: {filename}, Prediction: {'Varroa mite' if prediction == 1 else 'No mite'}\")\n",
    "\n",
    "# Example usage\n",
    "image_folder = './dataset/images'\n",
    "process_images(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "Filename: IMG_5536.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5559.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Filename: IMG_5560.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Filename: IMG_5561.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Filename: IMG_5562.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Filename: IMG_5582.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Filename: IMG_5583.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Filename: IMG_5584.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Filename: IMG_5585.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Filename: IMG_5629.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Filename: IMG_5630.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Filename: IMG_5631.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5651.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Filename: IMG_5652.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Filename: IMG_5654.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Filename: IMG_5674.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Filename: IMG_5675.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Filename: IMG_5676.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Filename: IMG_5677.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5699.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Filename: IMG_5700.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Filename: IMG_5701.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Filename: IMG_5702.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "Filename: IMG_5722.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Filename: IMG_5723.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Filename: IMG_5724.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5725.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Filename: IMG_5745.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Filename: IMG_5746.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Filename: IMG_5747.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Filename: IMG_5748.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Filename: IMG_5769.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Filename: IMG_5770.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Filename: IMG_5771.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "Filename: IMG_5791.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Filename: IMG_5792.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Filename: IMG_5793.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Filename: IMG_5794.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Filename: IMG_5814.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Filename: IMG_5815.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Filename: IMG_5816.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5817.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Filename: IMG_5838.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Filename: IMG_5861.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Filename: IMG_5862.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Filename: IMG_5863.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Filename: IMG_5864.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Filename: IMG_5884.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Filename: IMG_5885.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Filename: IMG_5887.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Filename: IMG_5907.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Filename: IMG_5908.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Filename: IMG_5909.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Filename: IMG_5910.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Filename: IMG_5956.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Filename: IMG_5957.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Filename: IMG_5958.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Filename: IMG_5959.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Filename: IMG_5979.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Filename: IMG_5980.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Filename: IMG_5981.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Filename: IMG_5982.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Filename: IMG_5993.jpg, Prediction: No mite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Filename: IMG_5994.jpg, Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('mite_classifier_model.h5')\n",
    "\n",
    "def predict_image(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    prediction = model.predict(img)\n",
    "    return np.argmax(prediction, axis=1)\n",
    "\n",
    "# Function to process all images in a folder\n",
    "def process_images(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            prediction = predict_image(image_path, model)\n",
    "            print(f\"Filename: {filename}, Prediction: {'Varroa mite' if prediction == 1 else 'No mite'}\")\n",
    "\n",
    "# Example usage\n",
    "image_folder = './dataset/images'\n",
    "process_images(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=./models/0070_fasterrcnn_resnet50_fpn_th50/modelo.bin. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(./models/0070_fasterrcnn_resnet50_fpn_th50/modelo.bin, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/0070_fasterrcnn_resnet50_fpn_th50/modelo.bin\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Directory containing saved_model.pb and variables/\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Define a function to parse XML and extract label (for testing purposes)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_xml\u001b[39m(label_path):\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:199\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that the legacy SavedModel format is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference-only layer in Keras 3, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.layers.TFSMLayer(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, call_endpoint=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(note that your `call_endpoint` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File format not supported: filepath=./models/0070_fasterrcnn_resnet50_fpn_th50/modelo.bin. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(./models/0070_fasterrcnn_resnet50_fpn_th50/modelo.bin, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Assuming the model is in the TensorFlow SavedModel format\n",
    "model_path = './models/0070_fasterrcnn_resnet50_fpn_th50/modelo.bin'  # Directory containing saved_model.pb and variables/\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Define a function to parse XML and extract label (for testing purposes)\n",
    "def parse_xml(label_path):\n",
    "    tree = ET.parse(label_path)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        return 1 if label == 'varroa_mite' else 0\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(128, 128))\n",
    "    img = image.img_to_array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# Function to make prediction on a single image\n",
    "def predict_image(image_path, model):\n",
    "    img = preprocess_image(image_path)\n",
    "    prediction = model.predict(img)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    return 'Varroa mite' if predicted_class == 1 else 'No mite'\n",
    "\n",
    "# Example usage\n",
    "image_path = './dataset/images/IMG_5994.jpg'\n",
    "prediction = predict_image(image_path, model)\n",
    "print('Prediction:', prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/0070_fasterrcnn_resnet50_fpn_th50/modelo.bin\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Function to preprocess a single image\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Load the PyTorch model\n",
    "model_path = './models/0070_fasterrcnn_resnet50_fpn_th50/modelo.bin'\n",
    "model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(128, 128))\n",
    "    img = image.img_to_array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# Define a function to parse XML and extract label (for testing purposes)\n",
    "def parse_xml(label_path):\n",
    "    tree = ET.parse(label_path)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        return 1 if label == 'varroa_mite' else 0\n",
    "\n",
    "# Convert PyTorch model predictions to numpy\n",
    "def predict_image(image_path, model):\n",
    "    img = preprocess_image(image_path)\n",
    "    img = torch.tensor(img).permute(0, 3, 1, 2).float()  # Convert to PyTorch tensor and reshape\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img)\n",
    "    predicted_class = np.argmax(prediction.numpy(), axis=1)\n",
    "    return 'Varroa mite' if predicted_class == 1 else 'No mite'\n",
    "\n",
    "# Example usage\n",
    "image_path = 'path_to_new_image.jpg'\n",
    "prediction = predict_image(image_path, model)\n",
    "print('Prediction:', prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# Function to get the FasterRCNN model with ResNet50 backbone\n",
    "def get_model():\n",
    "    # Load a pre-trained FasterRCNN model\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "    \n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one (2 classes: background and varroa mite)\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Load the model architecture\n",
    "model = get_model()\n",
    "\n",
    "# Load the state dictionary\n",
    "model_path = './models/0070_fasterrcnn_resnet50_fpn_th50/modelo.bin'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision import transforms\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Function to parse XML and extract label (for testing purposes)\n",
    "def parse_xml(label_path):\n",
    "    tree = ET.parse(label_path)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        return 1 if label == 'varroa_mite' else 0\n",
    "\n",
    "# Convert PyTorch model predictions to numpy\n",
    "def predict_image(image_path, model):\n",
    "    img = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img)\n",
    "    \n",
    "    # Extract the class with the highest score\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    scores = prediction[0]['scores'].cpu().numpy()\n",
    "    labels = prediction[0]['labels'].cpu().numpy()\n",
    "    \n",
    "    # Thresholding based on a score (for instance, 0.5)\n",
    "    threshold = 0.5\n",
    "    indices = np.where(scores > threshold)[0]\n",
    "    \n",
    "    # Check if any labels indicate the presence of Varroa mite (class 1)\n",
    "    has_varroa_mite = any(labels[idx] == 1 for idx in indices)\n",
    "    \n",
    "    return 'Varroa mite' if has_varroa_mite else 'No mite'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path = './dataset/images/IMG_5994.jpg'\n",
    "prediction = predict_image(image_path, model)\n",
    "print('Prediction:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: IMG_5536.jpg, Prediction: No mite\n",
      "Filename: IMG_5559.jpg, Prediction: No mite\n",
      "Filename: IMG_5560.jpg, Prediction: No mite\n",
      "Filename: IMG_5561.jpg, Prediction: No mite\n",
      "Filename: IMG_5562.jpg, Prediction: No mite\n",
      "Filename: IMG_5582.jpg, Prediction: No mite\n",
      "Filename: IMG_5583.jpg, Prediction: No mite\n",
      "Filename: IMG_5584.jpg, Prediction: No mite\n",
      "Filename: IMG_5585.jpg, Prediction: No mite\n",
      "Filename: IMG_5629.jpg, Prediction: No mite\n",
      "Filename: IMG_5630.jpg, Prediction: No mite\n",
      "Filename: IMG_5631.jpg, Prediction: No mite\n",
      "Filename: IMG_5651.jpg, Prediction: No mite\n",
      "Filename: IMG_5652.jpg, Prediction: No mite\n",
      "Filename: IMG_5654.jpg, Prediction: No mite\n",
      "Filename: IMG_5674.jpg, Prediction: No mite\n",
      "Filename: IMG_5675.jpg, Prediction: No mite\n",
      "Filename: IMG_5676.jpg, Prediction: No mite\n",
      "Filename: IMG_5677.jpg, Prediction: No mite\n",
      "Filename: IMG_5699.jpg, Prediction: No mite\n",
      "Filename: IMG_5700.jpg, Prediction: No mite\n",
      "Filename: IMG_5701.jpg, Prediction: No mite\n",
      "Filename: IMG_5702.jpg, Prediction: No mite\n",
      "Filename: IMG_5722.jpg, Prediction: No mite\n",
      "Filename: IMG_5723.jpg, Prediction: No mite\n",
      "Filename: IMG_5724.jpg, Prediction: No mite\n",
      "Filename: IMG_5725.jpg, Prediction: No mite\n",
      "Filename: IMG_5745.jpg, Prediction: No mite\n",
      "Filename: IMG_5746.jpg, Prediction: No mite\n",
      "Filename: IMG_5747.jpg, Prediction: No mite\n",
      "Filename: IMG_5748.jpg, Prediction: No mite\n",
      "Filename: IMG_5769.jpg, Prediction: No mite\n",
      "Filename: IMG_5770.jpg, Prediction: No mite\n",
      "Filename: IMG_5771.jpg, Prediction: No mite\n",
      "Filename: IMG_5791.jpg, Prediction: No mite\n",
      "Filename: IMG_5792.jpg, Prediction: No mite\n",
      "Filename: IMG_5793.jpg, Prediction: No mite\n",
      "Filename: IMG_5794.jpg, Prediction: No mite\n",
      "Filename: IMG_5814.jpg, Prediction: No mite\n",
      "Filename: IMG_5815.jpg, Prediction: No mite\n",
      "Filename: IMG_5816.jpg, Prediction: No mite\n",
      "Filename: IMG_5817.jpg, Prediction: No mite\n",
      "Filename: IMG_5838.jpg, Prediction: No mite\n",
      "Filename: IMG_5861.jpg, Prediction: No mite\n",
      "Filename: IMG_5862.jpg, Prediction: No mite\n",
      "Filename: IMG_5863.jpg, Prediction: No mite\n",
      "Filename: IMG_5864.jpg, Prediction: No mite\n",
      "Filename: IMG_5884.jpg, Prediction: No mite\n",
      "Filename: IMG_5885.jpg, Prediction: No mite\n",
      "Filename: IMG_5887.jpg, Prediction: No mite\n",
      "Filename: IMG_5907.jpg, Prediction: No mite\n",
      "Filename: IMG_5908.jpg, Prediction: No mite\n",
      "Filename: IMG_5909.jpg, Prediction: No mite\n",
      "Filename: IMG_5910.jpg, Prediction: No mite\n",
      "Filename: IMG_5956.jpg, Prediction: No mite\n",
      "Filename: IMG_5957.jpg, Prediction: No mite\n",
      "Filename: IMG_5958.jpg, Prediction: No mite\n",
      "Filename: IMG_5959.jpg, Prediction: No mite\n",
      "Filename: IMG_5979.jpg, Prediction: No mite\n",
      "Filename: IMG_5980.jpg, Prediction: No mite\n",
      "Filename: IMG_5981.jpg, Prediction: No mite\n",
      "Filename: IMG_5982.jpg, Prediction: No mite\n",
      "Filename: IMG_5993.jpg, Prediction: No mite\n",
      "Filename: IMG_5994.jpg, Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def process_images(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            prediction = predict_image(image_path, model)\n",
    "            print(f\"Filename: {filename}, Prediction: {prediction}\")\n",
    "\n",
    "# Example usage\n",
    "image_folder = './dataset/images'\n",
    "process_images(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# Function to get the FasterRCNN model with ResNet50 backbone\n",
    "def get_model():\n",
    "    # Load a pre-trained FasterRCNN model\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "    \n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one (2 classes: background and varroa mite)\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Load the model architecture\n",
    "model = get_model()\n",
    "\n",
    "# Load the state dictionary\n",
    "model_path = './models/0094_fasterrcnn_resnet50_fpn_deblurGAN/modelo.bin'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision import transforms\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Function to parse XML and extract label (for testing purposes)\n",
    "def parse_xml(label_path):\n",
    "    tree = ET.parse(label_path)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        return 1 if label == 'varroa_mite' else 0\n",
    "\n",
    "# Convert PyTorch model predictions to numpy\n",
    "def predict_image(image_path, model):\n",
    "    img = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img)\n",
    "    \n",
    "    # Extract the class with the highest score\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    scores = prediction[0]['scores'].cpu().numpy()\n",
    "    labels = prediction[0]['labels'].cpu().numpy()\n",
    "    \n",
    "    # Thresholding based on a score (for instance, 0.5)\n",
    "    threshold = 0.5\n",
    "    indices = np.where(scores > threshold)[0]\n",
    "    \n",
    "    # Check if any labels indicate the presence of Varroa mite (class 1)\n",
    "    has_varroa_mite = any(labels[idx] == 1 for idx in indices)\n",
    "    \n",
    "    return 'Varroa mite' if has_varroa_mite else 'No mite'\n",
    "\n",
    "# Example usage\n",
    "image_path = './dataset/images/IMG_5994.jpg'\n",
    "prediction = predict_image(image_path, model)\n",
    "print('Prediction:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: IMG_5536.jpg, Prediction: No mite\n",
      "Filename: IMG_5559.jpg, Prediction: No mite\n",
      "Filename: IMG_5560.jpg, Prediction: No mite\n",
      "Filename: IMG_5561.jpg, Prediction: No mite\n",
      "Filename: IMG_5562.jpg, Prediction: No mite\n",
      "Filename: IMG_5582.jpg, Prediction: No mite\n",
      "Filename: IMG_5583.jpg, Prediction: No mite\n",
      "Filename: IMG_5584.jpg, Prediction: No mite\n",
      "Filename: IMG_5585.jpg, Prediction: No mite\n",
      "Filename: IMG_5629.jpg, Prediction: No mite\n",
      "Filename: IMG_5630.jpg, Prediction: No mite\n",
      "Filename: IMG_5631.jpg, Prediction: No mite\n",
      "Filename: IMG_5651.jpg, Prediction: No mite\n",
      "Filename: IMG_5652.jpg, Prediction: No mite\n",
      "Filename: IMG_5654.jpg, Prediction: No mite\n",
      "Filename: IMG_5674.jpg, Prediction: No mite\n",
      "Filename: IMG_5675.jpg, Prediction: No mite\n",
      "Filename: IMG_5676.jpg, Prediction: No mite\n",
      "Filename: IMG_5677.jpg, Prediction: No mite\n",
      "Filename: IMG_5699.jpg, Prediction: No mite\n",
      "Filename: IMG_5700.jpg, Prediction: No mite\n",
      "Filename: IMG_5701.jpg, Prediction: No mite\n",
      "Filename: IMG_5702.jpg, Prediction: No mite\n",
      "Filename: IMG_5722.jpg, Prediction: No mite\n",
      "Filename: IMG_5723.jpg, Prediction: No mite\n",
      "Filename: IMG_5724.jpg, Prediction: No mite\n",
      "Filename: IMG_5725.jpg, Prediction: No mite\n",
      "Filename: IMG_5745.jpg, Prediction: No mite\n",
      "Filename: IMG_5746.jpg, Prediction: No mite\n",
      "Filename: IMG_5747.jpg, Prediction: No mite\n",
      "Filename: IMG_5748.jpg, Prediction: No mite\n",
      "Filename: IMG_5769.jpg, Prediction: No mite\n",
      "Filename: IMG_5770.jpg, Prediction: No mite\n",
      "Filename: IMG_5771.jpg, Prediction: No mite\n",
      "Filename: IMG_5791.jpg, Prediction: No mite\n",
      "Filename: IMG_5792.jpg, Prediction: No mite\n",
      "Filename: IMG_5793.jpg, Prediction: No mite\n",
      "Filename: IMG_5794.jpg, Prediction: No mite\n",
      "Filename: IMG_5814.jpg, Prediction: No mite\n",
      "Filename: IMG_5815.jpg, Prediction: No mite\n",
      "Filename: IMG_5816.jpg, Prediction: No mite\n",
      "Filename: IMG_5817.jpg, Prediction: No mite\n",
      "Filename: IMG_5838.jpg, Prediction: No mite\n",
      "Filename: IMG_5861.jpg, Prediction: No mite\n",
      "Filename: IMG_5862.jpg, Prediction: No mite\n",
      "Filename: IMG_5863.jpg, Prediction: No mite\n",
      "Filename: IMG_5864.jpg, Prediction: No mite\n",
      "Filename: IMG_5884.jpg, Prediction: No mite\n",
      "Filename: IMG_5885.jpg, Prediction: No mite\n",
      "Filename: IMG_5887.jpg, Prediction: No mite\n",
      "Filename: IMG_5907.jpg, Prediction: No mite\n",
      "Filename: IMG_5908.jpg, Prediction: No mite\n",
      "Filename: IMG_5909.jpg, Prediction: No mite\n",
      "Filename: IMG_5910.jpg, Prediction: No mite\n",
      "Filename: IMG_5956.jpg, Prediction: No mite\n",
      "Filename: IMG_5957.jpg, Prediction: No mite\n",
      "Filename: IMG_5958.jpg, Prediction: No mite\n",
      "Filename: IMG_5959.jpg, Prediction: No mite\n",
      "Filename: IMG_5979.jpg, Prediction: No mite\n",
      "Filename: IMG_5980.jpg, Prediction: No mite\n",
      "Filename: IMG_5981.jpg, Prediction: No mite\n",
      "Filename: IMG_5982.jpg, Prediction: No mite\n",
      "Filename: IMG_5993.jpg, Prediction: No mite\n",
      "Filename: IMG_5994.jpg, Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def process_images(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            prediction = predict_image(image_path, model)\n",
    "            print(f\"Filename: {filename}, Prediction: {prediction}\")\n",
    "\n",
    "# Example usage\n",
    "image_folder = './dataset/images'\n",
    "process_images(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FasterRCNN:\n\tsize mismatch for backbone.fpn.inner_blocks.0.0.weight: copying a param with shape torch.Size([256, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Ensure the state dictionary keys match the model keys\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FasterRCNN:\n\tsize mismatch for backbone.fpn.inner_blocks.0.0.weight: copying a param with shape torch.Size([256, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "\n",
    "# Function to create the Faster R-CNN model with a ResNet-18 backbone\n",
    "def get_model():\n",
    "    # Load a pre-trained ResNet-18 model\n",
    "    backbone = resnet18(pretrained=True)\n",
    "    # Replace the fully connected layer with an identity function\n",
    "    backbone.fc = torch.nn.Identity()\n",
    "    \n",
    "    # Use the backbone as a feature extractor for Faster R-CNN\n",
    "    backbone = torchvision.models.detection.backbone_utils.BackboneWithFPN(backbone, return_layers={'layer4': 0}, in_channels_list=[512], out_channels=256)\n",
    "\n",
    "    # Load Faster R-CNN with the custom backbone\n",
    "    model = FasterRCNN(backbone, num_classes=2)  # 2 classes: background and varroa mite\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load the model architecture\n",
    "model = get_model()\n",
    "\n",
    "# Load the state dictionary\n",
    "model_path = './models/0096_resnet18_fpn_th50/modelo.bin'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Ensure the state dictionary keys match the model keys\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision import transforms\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Function to parse XML and extract label (for testing purposes)\n",
    "def parse_xml(label_path):\n",
    "    tree = ET.parse(label_path)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        return 1 if label == 'varroa_mite' else 0\n",
    "\n",
    "# Convert PyTorch model predictions to numpy\n",
    "def predict_image(image_path, model):\n",
    "    img = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img)\n",
    "    \n",
    "    # Extract the class with the highest score\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    scores = prediction[0]['scores'].cpu().numpy()\n",
    "    labels = prediction[0]['labels'].cpu().numpy()\n",
    "    \n",
    "    # Thresholding based on a score (for instance, 0.5)\n",
    "    threshold = 0.5\n",
    "    indices = np.where(scores > threshold)[0]\n",
    "    \n",
    "    # Check if any labels indicate the presence of Varroa mite (class 1)\n",
    "    has_varroa_mite = any(labels[idx] == 1 for idx in indices)\n",
    "    \n",
    "    return 'Varroa mite' if has_varroa_mite else 'No mite'\n",
    "\n",
    "# Example usage\n",
    "image_path = './dataset/images/IMG_5994.jpg'\n",
    "prediction = predict_image(image_path, model)\n",
    "print('Prediction:', prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AI Projects\\Verona_Mites\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'backbone_name' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "\n",
    "# Function to get the FasterRCNN model with ResNet152 backbone\n",
    "def get_model():\n",
    "    # Load a ResNet152 backbone with FPN\n",
    "    backbone = resnet_fpn_backbone('resnet152', pretrained=False)\n",
    "    \n",
    "    # Create the FasterRCNN model with the custom backbone\n",
    "    model = torchvision.models.detection.FasterRCNN(backbone, num_classes=2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load the model architecture\n",
    "model = get_model()\n",
    "\n",
    "# Load the state dictionary\n",
    "model_path = './models/0104_resnet152_fpn_th50_deblurGAN/modelo.bin'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Convert PyTorch model predictions to numpy\n",
    "def predict_image(image_path, model):\n",
    "    img = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img)\n",
    "    \n",
    "    # Extract the class with the highest score\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    scores = prediction[0]['scores'].cpu().numpy()\n",
    "    labels = prediction[0]['labels'].cpu().numpy()\n",
    "    \n",
    "    # Thresholding based on a score (for instance, 0.5)\n",
    "    threshold = 0.5\n",
    "    indices = np.where(scores > threshold)[0]\n",
    "    \n",
    "    # Check if any labels indicate the presence of Varroa mite (class 1)\n",
    "    has_varroa_mite = any(labels[idx] == 1 for idx in indices)\n",
    "    \n",
    "    return 'Varroa mite' if has_varroa_mite else 'No mite'\n",
    "\n",
    "# Example usage\n",
    "image_path = './dataset/images/IMG_5994.jpg'\n",
    "prediction = predict_image(image_path, model)\n",
    "print('Prediction:', prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: IMG_5536.jpg, Prediction: No mite\n",
      "Filename: IMG_5559.jpg, Prediction: No mite\n",
      "Filename: IMG_5560.jpg, Prediction: No mite\n",
      "Filename: IMG_5561.jpg, Prediction: No mite\n",
      "Filename: IMG_5562.jpg, Prediction: No mite\n",
      "Filename: IMG_5582.jpg, Prediction: No mite\n",
      "Filename: IMG_5583.jpg, Prediction: No mite\n",
      "Filename: IMG_5584.jpg, Prediction: No mite\n",
      "Filename: IMG_5585.jpg, Prediction: No mite\n",
      "Filename: IMG_5629.jpg, Prediction: No mite\n",
      "Filename: IMG_5630.jpg, Prediction: No mite\n",
      "Filename: IMG_5631.jpg, Prediction: No mite\n",
      "Filename: IMG_5651.jpg, Prediction: No mite\n",
      "Filename: IMG_5652.jpg, Prediction: No mite\n",
      "Filename: IMG_5654.jpg, Prediction: No mite\n",
      "Filename: IMG_5674.jpg, Prediction: No mite\n",
      "Filename: IMG_5675.jpg, Prediction: No mite\n",
      "Filename: IMG_5676.jpg, Prediction: No mite\n",
      "Filename: IMG_5677.jpg, Prediction: No mite\n",
      "Filename: IMG_5699.jpg, Prediction: No mite\n",
      "Filename: IMG_5700.jpg, Prediction: No mite\n",
      "Filename: IMG_5701.jpg, Prediction: No mite\n",
      "Filename: IMG_5702.jpg, Prediction: No mite\n",
      "Filename: IMG_5722.jpg, Prediction: No mite\n",
      "Filename: IMG_5723.jpg, Prediction: No mite\n",
      "Filename: IMG_5724.jpg, Prediction: No mite\n",
      "Filename: IMG_5725.jpg, Prediction: No mite\n",
      "Filename: IMG_5745.jpg, Prediction: No mite\n",
      "Filename: IMG_5746.jpg, Prediction: No mite\n",
      "Filename: IMG_5747.jpg, Prediction: No mite\n",
      "Filename: IMG_5748.jpg, Prediction: No mite\n",
      "Filename: IMG_5769.jpg, Prediction: No mite\n",
      "Filename: IMG_5770.jpg, Prediction: No mite\n",
      "Filename: IMG_5771.jpg, Prediction: No mite\n",
      "Filename: IMG_5791.jpg, Prediction: No mite\n",
      "Filename: IMG_5792.jpg, Prediction: No mite\n",
      "Filename: IMG_5793.jpg, Prediction: No mite\n",
      "Filename: IMG_5794.jpg, Prediction: No mite\n",
      "Filename: IMG_5814.jpg, Prediction: No mite\n",
      "Filename: IMG_5815.jpg, Prediction: No mite\n",
      "Filename: IMG_5816.jpg, Prediction: No mite\n",
      "Filename: IMG_5817.jpg, Prediction: No mite\n",
      "Filename: IMG_5838.jpg, Prediction: No mite\n",
      "Filename: IMG_5861.jpg, Prediction: No mite\n",
      "Filename: IMG_5862.jpg, Prediction: No mite\n",
      "Filename: IMG_5863.jpg, Prediction: No mite\n",
      "Filename: IMG_5864.jpg, Prediction: No mite\n",
      "Filename: IMG_5884.jpg, Prediction: No mite\n",
      "Filename: IMG_5885.jpg, Prediction: No mite\n",
      "Filename: IMG_5887.jpg, Prediction: No mite\n",
      "Filename: IMG_5907.jpg, Prediction: No mite\n",
      "Filename: IMG_5908.jpg, Prediction: No mite\n",
      "Filename: IMG_5909.jpg, Prediction: No mite\n",
      "Filename: IMG_5910.jpg, Prediction: No mite\n",
      "Filename: IMG_5956.jpg, Prediction: No mite\n",
      "Filename: IMG_5957.jpg, Prediction: No mite\n",
      "Filename: IMG_5958.jpg, Prediction: No mite\n",
      "Filename: IMG_5959.jpg, Prediction: No mite\n",
      "Filename: IMG_5979.jpg, Prediction: No mite\n",
      "Filename: IMG_5980.jpg, Prediction: No mite\n",
      "Filename: IMG_5981.jpg, Prediction: No mite\n",
      "Filename: IMG_5982.jpg, Prediction: No mite\n",
      "Filename: IMG_5993.jpg, Prediction: No mite\n",
      "Filename: IMG_5994.jpg, Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def process_images(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            prediction = predict_image(image_path, model)\n",
    "            print(f\"Filename: {filename}, Prediction: {prediction}\")\n",
    "\n",
    "# Example usage\n",
    "image_folder = './dataset/images'\n",
    "process_images(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "\n",
    "# Function to get the FasterRCNN model with ResNet18 backbone\n",
    "def get_model():\n",
    "    # Load a pre-trained ResNet18 backbone\n",
    "    backbone = resnet_fpn_backbone('resnet18', pretrained=False)\n",
    "    \n",
    "    # Create the FasterRCNN model using the ResNet18 backbone\n",
    "    model = torchvision.models.detection.FasterRCNN(backbone, num_classes=2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load the model architecture\n",
    "model = get_model()\n",
    "\n",
    "# Load the state dictionary\n",
    "model_path = './models/0105_resnet18_fpn_th50_deblurGAN/modelo_7752.bin'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision import transforms\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Function to parse XML and extract label (for testing purposes)\n",
    "def parse_xml(label_path):\n",
    "    tree = ET.parse(label_path)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        return 1 if label == 'varroa_mite' else 0\n",
    "\n",
    "# Convert PyTorch model predictions to numpy\n",
    "def predict_image(image_path, model):\n",
    "    img = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img)\n",
    "    \n",
    "    # Extract the class with the highest score\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    scores = prediction[0]['scores'].cpu().numpy()\n",
    "    labels = prediction[0]['labels'].cpu().numpy()\n",
    "    \n",
    "    # Thresholding based on a score (for instance, 0.5)\n",
    "    threshold = 0.5\n",
    "    indices = np.where(scores > threshold)[0]\n",
    "    \n",
    "    # Check if any labels indicate the presence of Varroa mite (class 1)\n",
    "    has_varroa_mite = any(labels[idx] == 1 for idx in indices)\n",
    "    \n",
    "    return 'Varroa mite' if has_varroa_mite else 'No mite'\n",
    "\n",
    "# Example usage\n",
    "image_path = './dataset/images/IMG_5994.jpg'\n",
    "prediction = predict_image(image_path, model)\n",
    "print('Prediction:', prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: IMG_5536.jpg, Prediction: No mite\n",
      "Filename: IMG_5559.jpg, Prediction: No mite\n",
      "Filename: IMG_5560.jpg, Prediction: No mite\n",
      "Filename: IMG_5561.jpg, Prediction: No mite\n",
      "Filename: IMG_5562.jpg, Prediction: No mite\n",
      "Filename: IMG_5582.jpg, Prediction: No mite\n",
      "Filename: IMG_5583.jpg, Prediction: No mite\n",
      "Filename: IMG_5584.jpg, Prediction: No mite\n",
      "Filename: IMG_5585.jpg, Prediction: No mite\n",
      "Filename: IMG_5629.jpg, Prediction: No mite\n",
      "Filename: IMG_5630.jpg, Prediction: No mite\n",
      "Filename: IMG_5631.jpg, Prediction: No mite\n",
      "Filename: IMG_5651.jpg, Prediction: No mite\n",
      "Filename: IMG_5652.jpg, Prediction: No mite\n",
      "Filename: IMG_5654.jpg, Prediction: No mite\n",
      "Filename: IMG_5674.jpg, Prediction: No mite\n",
      "Filename: IMG_5675.jpg, Prediction: No mite\n",
      "Filename: IMG_5676.jpg, Prediction: No mite\n",
      "Filename: IMG_5677.jpg, Prediction: No mite\n",
      "Filename: IMG_5699.jpg, Prediction: No mite\n",
      "Filename: IMG_5700.jpg, Prediction: No mite\n",
      "Filename: IMG_5701.jpg, Prediction: No mite\n",
      "Filename: IMG_5702.jpg, Prediction: No mite\n",
      "Filename: IMG_5722.jpg, Prediction: No mite\n",
      "Filename: IMG_5723.jpg, Prediction: No mite\n",
      "Filename: IMG_5724.jpg, Prediction: No mite\n",
      "Filename: IMG_5725.jpg, Prediction: No mite\n",
      "Filename: IMG_5745.jpg, Prediction: No mite\n",
      "Filename: IMG_5746.jpg, Prediction: No mite\n",
      "Filename: IMG_5747.jpg, Prediction: No mite\n",
      "Filename: IMG_5748.jpg, Prediction: No mite\n",
      "Filename: IMG_5769.jpg, Prediction: No mite\n",
      "Filename: IMG_5770.jpg, Prediction: No mite\n",
      "Filename: IMG_5771.jpg, Prediction: No mite\n",
      "Filename: IMG_5791.jpg, Prediction: No mite\n",
      "Filename: IMG_5792.jpg, Prediction: No mite\n",
      "Filename: IMG_5793.jpg, Prediction: No mite\n",
      "Filename: IMG_5794.jpg, Prediction: No mite\n",
      "Filename: IMG_5814.jpg, Prediction: No mite\n",
      "Filename: IMG_5815.jpg, Prediction: No mite\n",
      "Filename: IMG_5816.jpg, Prediction: No mite\n",
      "Filename: IMG_5817.jpg, Prediction: No mite\n",
      "Filename: IMG_5838.jpg, Prediction: No mite\n",
      "Filename: IMG_5861.jpg, Prediction: No mite\n",
      "Filename: IMG_5862.jpg, Prediction: No mite\n",
      "Filename: IMG_5863.jpg, Prediction: No mite\n",
      "Filename: IMG_5864.jpg, Prediction: No mite\n",
      "Filename: IMG_5884.jpg, Prediction: No mite\n",
      "Filename: IMG_5885.jpg, Prediction: No mite\n",
      "Filename: IMG_5887.jpg, Prediction: No mite\n",
      "Filename: IMG_5907.jpg, Prediction: No mite\n",
      "Filename: IMG_5908.jpg, Prediction: No mite\n",
      "Filename: IMG_5909.jpg, Prediction: No mite\n",
      "Filename: IMG_5910.jpg, Prediction: No mite\n",
      "Filename: IMG_5956.jpg, Prediction: No mite\n",
      "Filename: IMG_5957.jpg, Prediction: No mite\n",
      "Filename: IMG_5958.jpg, Prediction: No mite\n",
      "Filename: IMG_5959.jpg, Prediction: No mite\n",
      "Filename: IMG_5979.jpg, Prediction: No mite\n",
      "Filename: IMG_5980.jpg, Prediction: No mite\n",
      "Filename: IMG_5981.jpg, Prediction: No mite\n",
      "Filename: IMG_5982.jpg, Prediction: No mite\n",
      "Filename: IMG_5993.jpg, Prediction: No mite\n",
      "Filename: IMG_5994.jpg, Prediction: No mite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def process_images(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            prediction = predict_image(image_path, model)\n",
    "            print(f\"Filename: {filename}, Prediction: {prediction}\")\n",
    "\n",
    "# Example usage\n",
    "image_folder = './dataset/images'\n",
    "process_images(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
