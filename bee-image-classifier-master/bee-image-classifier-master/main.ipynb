{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>location</th>\n",
       "      <th>zip code</th>\n",
       "      <th>subspecies</th>\n",
       "      <th>health</th>\n",
       "      <th>pollen_carrying</th>\n",
       "      <th>caste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>041_066.png</td>\n",
       "      <td>8/28/18</td>\n",
       "      <td>16:07</td>\n",
       "      <td>Alvin, TX, USA</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>041_072.png</td>\n",
       "      <td>8/28/18</td>\n",
       "      <td>16:07</td>\n",
       "      <td>Alvin, TX, USA</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041_073.png</td>\n",
       "      <td>8/28/18</td>\n",
       "      <td>16:07</td>\n",
       "      <td>Alvin, TX, USA</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>041_067.png</td>\n",
       "      <td>8/28/18</td>\n",
       "      <td>16:07</td>\n",
       "      <td>Alvin, TX, USA</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>041_059.png</td>\n",
       "      <td>8/28/18</td>\n",
       "      <td>16:07</td>\n",
       "      <td>Alvin, TX, USA</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>027_011.png</td>\n",
       "      <td>8/20/18</td>\n",
       "      <td>10:03</td>\n",
       "      <td>San Jose, CA, USA</td>\n",
       "      <td>95124</td>\n",
       "      <td>-1</td>\n",
       "      <td>healthy</td>\n",
       "      <td>True</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>027_007.png</td>\n",
       "      <td>8/20/18</td>\n",
       "      <td>10:03</td>\n",
       "      <td>San Jose, CA, USA</td>\n",
       "      <td>95124</td>\n",
       "      <td>-1</td>\n",
       "      <td>healthy</td>\n",
       "      <td>True</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>027_013.png</td>\n",
       "      <td>8/20/18</td>\n",
       "      <td>10:03</td>\n",
       "      <td>San Jose, CA, USA</td>\n",
       "      <td>95124</td>\n",
       "      <td>-1</td>\n",
       "      <td>healthy</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>027_012.png</td>\n",
       "      <td>8/20/18</td>\n",
       "      <td>10:03</td>\n",
       "      <td>San Jose, CA, USA</td>\n",
       "      <td>95124</td>\n",
       "      <td>-1</td>\n",
       "      <td>healthy</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>027_014.png</td>\n",
       "      <td>8/20/18</td>\n",
       "      <td>10:03</td>\n",
       "      <td>San Jose, CA, USA</td>\n",
       "      <td>95124</td>\n",
       "      <td>-1</td>\n",
       "      <td>healthy</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             file     date   time           location  zip code subspecies  \\\n",
       "0     041_066.png  8/28/18  16:07     Alvin, TX, USA     77511         -1   \n",
       "1     041_072.png  8/28/18  16:07     Alvin, TX, USA     77511         -1   \n",
       "2     041_073.png  8/28/18  16:07     Alvin, TX, USA     77511         -1   \n",
       "3     041_067.png  8/28/18  16:07     Alvin, TX, USA     77511         -1   \n",
       "4     041_059.png  8/28/18  16:07     Alvin, TX, USA     77511         -1   \n",
       "...           ...      ...    ...                ...       ...        ...   \n",
       "5167  027_011.png  8/20/18  10:03  San Jose, CA, USA     95124         -1   \n",
       "5168  027_007.png  8/20/18  10:03  San Jose, CA, USA     95124         -1   \n",
       "5169  027_013.png  8/20/18  10:03  San Jose, CA, USA     95124         -1   \n",
       "5170  027_012.png  8/20/18  10:03  San Jose, CA, USA     95124         -1   \n",
       "5171  027_014.png  8/20/18  10:03  San Jose, CA, USA     95124         -1   \n",
       "\n",
       "                 health  pollen_carrying   caste  \n",
       "0     hive being robbed            False  worker  \n",
       "1     hive being robbed            False  worker  \n",
       "2     hive being robbed            False  worker  \n",
       "3     hive being robbed            False  worker  \n",
       "4     hive being robbed            False  worker  \n",
       "...                 ...              ...     ...  \n",
       "5167            healthy             True  worker  \n",
       "5168            healthy             True  worker  \n",
       "5169            healthy            False  worker  \n",
       "5170            healthy            False  worker  \n",
       "5171            healthy            False  worker  \n",
       "\n",
       "[5172 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     27\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 28\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(image_path):\n\u001b[0;32m     30\u001b[0m         image \u001b[38;5;241m=\u001b[39m load_and_preprocess_image(image_path)\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "data_path = './bee_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "display(df)\n",
    "\n",
    "# Preprocess the images\n",
    "def load_and_preprocess_image(image_path, img_size=(128, 128)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, img_size)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row['file']\n",
    "    label = row['label']\n",
    "    if os.path.exists(image_path):\n",
    "        image = load_and_preprocess_image(image_path)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize images\n",
    "images = images / 255.0\n",
    "\n",
    "# Convert labels to categorical\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # Assuming 10 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Save the model\n",
    "model.save('object_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached torchvision-0.19.0-1-cp310-cp310-win_amd64.whl (1.3 MB)\n",
      "Requirement already satisfied: torch==2.4.0 in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from torchvision) (2.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: numpy<2 in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: sympy in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from torch==2.4.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: filelock in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from torch==2.4.0->torchvision) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from torch==2.4.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: fsspec in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: networkx in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from torch==2.4.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\ai projects\\verona_mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ibtasam Ahmad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Ibtasam Ahmad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"e:\\AI Projects\\Verona_Mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\Scripts\\pip.exe\\__main__.py\", line 4, in <module>\n",
      "ModuleNotFoundError: No module named 'pip'\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall torch\n",
    "! pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"e:\\AI Projects\\Verona_Mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI Projects\\Verona_Mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages\\torch\\__init__.py:148\u001b[0m\n\u001b[0;32m    146\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    147\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    150\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"e:\\AI Projects\\Verona_Mites\\bee-image-classifier-master\\bee-image-classifier-master\\env\\lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from pathlib import Path, PurePath\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import  xml.dom.minidom as minidom\n",
    "import xmltodict\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
